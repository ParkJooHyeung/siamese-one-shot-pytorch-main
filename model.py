# # CNN
# import torch
# import torch.nn as nn
#
#
# class SiameseNet(nn.Module):
#     """
#     A Convolutional Siamese Network for One-Shot Learning.
#
#     Siamese networts learn image representations via a supervised metric-based
#     approach. Once tuned, their learned features can be leveraged for one-shot
#     learning without any retraining.
#
#     References
#     ----------
#     - Koch et al., https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf
#     """
#
#     def __init__(self):
#         super(SiameseNet, self).__init__()
#         self.conv = nn.Sequential(
#             nn.Conv2d(1, 64, kernel_size=9),
#             nn.ReLU(inplace=True),
#             nn.MaxPool2d(2),
#             nn.Conv2d(64, 128, kernel_size=7),
#             nn.ReLU(inplace=True),
#             nn.MaxPool2d(2),
#             nn.Conv2d(128, 128, kernel_size=5),
#             nn.ReLU(inplace=True),
#             nn.MaxPool2d(2),
#             nn.Conv2d(128, 256, kernel_size=3),
#             nn.ReLU(inplace=True)
#         )
#         # 마지막 컨볼루션 층의 출력 크기에 맞게 조정해야 할 수 있음
#         self.liner = nn.Sequential(
#             nn.Dropout(0.5),  # 여기에 Dropout 추가
#             nn.Linear(256 * 6 * 6, 4096),
#             nn.Sigmoid()
#         )
#         self.out = nn.Linear(4096, 1)
#
#         # weight init
#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 nn.init.kaiming_uniform_(m.weight)
#             elif isinstance(m, nn.Linear):
#                 nn.init.xavier_uniform_(m.weight)
#
#     def sub_forward(self, x):
#         """
#         Forward pass the input image through 1 subnetwork.
#
#         Args
#         ----
#         - x: a Variable of size (B, C, H, W). Contains either the first or
#           second image pair across the input batch.
#
#         Returns
#         -------
#         - out: a Variable of size (B, 4096). The hidden vector representation
#           of the input vector x.
#         """
#         x = self.conv(x)
#         x = x.view(x.size()[0], -1)
#         x = self.liner(x)
#         return x
#
#     def forward(self, x1, x2):
#         """
#         Forward pass the input image pairs through both subtwins. An image
#         pair is composed of a left tensor x1 and a right tensor x2.
#
#         Concretely, we compute the component-wise L1 distance of the hidden
#         representations generated by each subnetwork, and feed the difference
#         to a final fc-layer followed by a sigmoid activation function to
#         generate a similarity score in the range [0, 1] for both embeddings.
#
#         Args
#         ----
#         - x1: a Variable of size (B, C, H, W). The left image pairs along the
#           batch dimension.
#         - x2: a Variable of size (B, C, H, W). The right image pairs along the
#           batch dimension.
#
#         Returns
#         -------
#         - probas: a Variable of size (B, 1). A probability scalar indicating
#           whether the left and right input pairs, along the batch dimension,
#           correspond to the same class. We expect the network to spit out
#           values near 1 when they belong to the same class, and 0 otherwise.
#         """
#         # encode image pairs
#         h1 = self.sub_forward(x1)
#         h2 = self.sub_forward(x2)
#
#         # compute l1 distance
#         diff = torch.abs(h1 - h2)
#
#         # score the similarity between the 2 encodings
#         scores = self.out(diff)
#
#         # return scores (without sigmoid) and use bce_with_logit
#         # for increased numerical stability
#         return scores
#
#
# if __name__ == '__main__':
#     net = SiameseNet()
#     print(net)

# Resnet_18
import torch
import torch.nn as nn
from torchvision.models import resnet18, ResNet18_Weights

class SiameseNet(nn.Module):
    """
    A Convolutional Siamese Network for One-Shot Learning using ResNet18 as the backbone.

    This network is adapted to accept grayscale (1-channel) images by modifying
    the first convolutional layer of the ResNet18 backbone to have 1 input channel.

    References
    ----------
    - Koch et al., https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf
    """

    def __init__(self):
        super(SiameseNet, self).__init__()

        # Load the pre-trained ResNet18 model as the backbone for the Siamese Network
        backbone = resnet18(weights=ResNet18_Weights.DEFAULT)
        # Modify the first convolutional layer to accept 1-channel (grayscale) images
        backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)

        self.features = nn.Sequential(*list(backbone.children())[:-2])  # Remove the last fully connected layer and global average pooling

        # Add an adaptive average pooling to handle different input sizes
        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))

        # Define the linear layer
        self.liner = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(512, 4096),  # ResNet18 features size is 512
            nn.Sigmoid()
        )

        self.out = nn.Linear(4096, 1)

    def sub_forward(self, x):
        """
        Forward pass the input image through 1 subnetwork, using the modified ResNet18 backbone.

        Args
        - x: a Variable of size (B, C, H, W). Contains either the first or
          second image pair across the input batch.

        Returns
        - out: a Variable of size (B, 4096). The hidden vector representation
          of the input vector x.
        """
        x = self.features(x)
        x = self.adaptive_pool(x)
        x = torch.flatten(x, 1)
        x = self.liner(x)
        return x

    def forward(self, x1, x2):
        """
        Forward pass the input image pairs through both subtwins using the modified ResNet18 backbone.

        Args
        - x1: a Variable of size (B, C, H, W). The left image pairs along the
          batch dimension.
        - x2: a Variable of size (B, C, H, W). The right image pairs along the
          batch dimension.

        Returns
        - scores: a Variable of size (B, 1). A score indicating the similarity
          of the input pairs.
        """
        h1 = self.sub_forward(x1)
        h2 = self.sub_forward(x2)

        # Compute L1 distance
        diff = torch.abs(h1 - h2)

        # Score the similarity between the 2 encodings
        scores = self.out(diff)

        return scores


if __name__ == '__main__':
    net = SiameseNet()
    print(net)

#ResNet50
# import torch
# import torch.nn as nn
# import torchvision.models as models
#
# class SiameseNet(nn.Module):
#     """
#     A Convolutional Siamese Network for One-Shot Learning using ResNet50 as the backbone.
#
#     This network is adapted to accept grayscale (1-channel) images by modifying
#     the first convolutional layer of the ResNet50 backbone to have 1 input channel.
#
#     References
#     ----------
#     - Koch et al., https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf
#     """
#
#     def __init__(self):
#         super(SiameseNet, self).__init__()
#
#         # Load the pre-trained ResNet50 model as the backbone for the Siamese Network
#         backbone = models.resnet50(pretrained=True)
#         # Modify the first convolutional layer to accept 1-channel (grayscale) images
#         backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
#
#         self.features = nn.Sequential(*list(backbone.children())[:-2])  # Remove the last fully connected layer and global average pooling
#
#         # Add an adaptive average pooling to handle different input sizes
#         self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
#
#         # Define the linear layer
#         # Note: The input size to the linear layer may need to be adjusted based on the output size of the adaptive pooling layer
#         self.liner = nn.Sequential(
#             nn.Dropout(0.5),
#             nn.Linear(2048, 4096),  # ResNet50 features size is 2048
#             nn.Sigmoid()
#         )
#
#         self.out = nn.Linear(4096, 1)
#
#     def sub_forward(self, x):
#         """
#         Forward pass the input image through 1 subnetwork, using the modified ResNet50 backbone.
#
#         Args
#         - x: a Variable of size (B, C, H, W). Contains either the first or
#           second image pair across the input batch.
#
#         Returns
#         - out: a Variable of size (B, 4096). The hidden vector representation
#           of the input vector x.
#         """
#         x = self.features(x)
#         x = self.adaptive_pool(x)
#         x = torch.flatten(x, 1)
#         x = self.liner(x)
#         return x
#
#     def forward(self, x1, x2):
#         """
#         Forward pass the input image pairs through both subtwins using the modified ResNet50 backbone.
#
#         Args
#         - x1: a Variable of size (B, C, H, W). The left image pairs along the
#           batch dimension.
#         - x2: a Variable of size (B, C, H, W). The right image pairs along the
#           batch dimension.
#
#         Returns
#         - scores: a Variable of size (B, 1). A score indicating the similarity
#           of the input pairs.
#         """
#         h1 = self.sub_forward(x1)
#         h2 = self.sub_forward(x2)
#
#         # Compute L1 distance
#         diff = torch.abs(h1 - h2)
#
#         # Score the similarity between the 2 encodings
#         scores = self.out(diff)
#
#         return scores
#
#
# if __name__ == '__main__':
#     net = SiameseNet()
#     print(net)

#ResNet34
# import torch
# import torch.nn as nn
# import torchvision.models as models
#
# class SiameseNet(nn.Module):
#     """
#     A Convolutional Siamese Network for One-Shot Learning using ResNet34 as the backbone.
#
#     This network is adapted to accept grayscale (1-channel) images by modifying
#     the first convolutional layer of the ResNet34 backbone to have 1 input channel.
#
#     References
#     ----------
#     - Koch et al., https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf
#     """
#
#     def __init__(self):
#         super(SiameseNet, self).__init__()
#
#         # Load the pre-trained ResNet34 model as the backbone for the Siamese Network
#         backbone = models.resnet34(pretrained=True)
#         # Modify the first convolutional layer to accept 1-channel (grayscale) images
#         backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
#
#         self.features = nn.Sequential(*list(backbone.children())[:-2])  # Remove the last fully connected layer and global average pooling
#
#         # Add an adaptive average pooling to handle different input sizes
#         self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
#
#         # Define the linear layer
#         # Adjust the input size of the linear layer according to the output size of the adaptive pooling layer for ResNet34
#         self.liner = nn.Sequential(
#             nn.Dropout(0.2),
#             nn.Linear(512, 4096),  # ResNet34 features size is 512
#             nn.Sigmoid()
#         )
#
#         self.out = nn.Linear(4096, 1)
#
#     def sub_forward(self, x):
#         """
#         Forward pass the input image through 1 subnetwork, using the modified ResNet34 backbone.
#
#         Args
#         - x: a Variable of size (B, C, H, W). Contains either the first or
#           second image pair across the input batch.
#
#         Returns
#         - out: a Variable of size (B, 4096). The hidden vector representation
#           of the input vector x.
#         """
#         x = self.features(x)
#         x = self.adaptive_pool(x)
#         x = torch.flatten(x, 1)
#         x = self.liner(x)
#         return x
#
#     def forward(self, x1, x2):
#         """
#         Forward pass the input image pairs through both subtwins using the modified ResNet34 backbone.
#
#         Args
#         - x1: a Variable of size (B, C, H, W). The left image pairs along the
#           batch dimension.
#         - x2: a Variable of size (B, C, H, W). The right image pairs along the
#           batch dimension.
#
#         Returns
#         - scores: a Variable of size (B, 1). A score indicating the similarity
#           of the input pairs.
#         """
#         h1 = self.sub_forward(x1)
#         h2 = self.sub_forward(x2)
#
#         # Compute L1 distance
#         diff = torch.abs(h1 - h2)
#
#         # Score the similarity between the 2 encodings
#         scores = self.out(diff)
#
#         return scores
#
#
# if __name__ == '__main__':
#     net = SiameseNet()
#     print(net)

#Resnet101
import torch
import torch.nn as nn
import torchvision.models as models

# class SiameseNet(nn.Module):
#     """
#     A Convolutional Siamese Network for One-Shot Learning using ResNet101 as the backbone.
#
#     This network is adapted to accept grayscale (1-channel) images by modifying
#     the first convolutional layer of the ResNet101 backbone to have 1 input channel.
#
#     References
#     ----------
#     - Koch et al., https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf
#     """
#
#     def __init__(self):
#         super(SiameseNet, self).__init__()
#
#         # Load the pre-trained ResNet101 model as the backbone for the Siamese Network
#         backbone = models.resnet101(pretrained=True)
#         # Modify the first convolutional layer to accept 1-channel (grayscale) images
#         backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
#
#         self.features = nn.Sequential(*list(backbone.children())[:-2])  # Remove the last fully connected layer and global average pooling
#
#         # Add an adaptive average pooling to handle different input sizes
#         self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
#
#         # Define the linear layer
#         # Adjust the input size of the linear layer according to the output size of the adaptive pooling layer for ResNet101
#         self.liner = nn.Sequential(
#             nn.Dropout(0.2),
#             nn.Linear(2048, 4096),  # ResNet101 features size is 2048
#             nn.Sigmoid()
#         )
#
#         self.out = nn.Linear(4096, 1)
#
#     def sub_forward(self, x):
#         """
#         Forward pass the input image through 1 subnetwork, using the modified ResNet101 backbone.
#
#         Args
#         - x: a Variable of size (B, C, H, W). Contains either the first or
#           second image pair across the input batch.
#
#         Returns
#         - out: a Variable of size (B, 4096). The hidden vector representation
#           of the input vector x.
#         """
#         x = self.features(x)
#         x = self.adaptive_pool(x)
#         x = torch.flatten(x, 1)
#         x = self.liner(x)
#         return x
#
#     def forward(self, x1, x2):
#         """
#         Forward pass the input image pairs through both subtwins using the modified ResNet101 backbone.
#
#         Args
#         - x1: a Variable of size (B, C, H, W). The left image pairs along the
#           batch dimension.
#         - x2: a Variable of size (B, C, H, W). The right image pairs along the
#           batch dimension.
#
#         Returns
#         - scores: a Variable of size (B, 1). A score indicating the similarity
#           of the input pairs.
#         """
#         h1 = self.sub_forward(x1)
#         h2 = self.sub_forward(x2)
#
#         # Compute L1 distance
#         diff = torch.abs(h1 - h2)
#
#         # Score the similarity between the 2 encodings
#         scores = self.out(diff)
#
#         return scores
#
#
# if __name__ == '__main__':
#     net = SiameseNet()
#     print(net)
